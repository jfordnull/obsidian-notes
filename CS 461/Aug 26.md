We expect AI systems to act logically and rationally more than we expect them to act *humanly*. 

Turing's argument puts emphasis on output by anonymizing input; disregards origination, internal processes in favor of external appearance of intelligence. Ship of Theseus argument: are the things the same if the internal components differ?

How do we think about likes, preferences, affinity in structuring our personalities? What about the emotional side of intelligence?

The Uncanny: human-like performance, but not quite human, like an animated corpse

Roko's Basilisk

Development of AI less about automated task-execution than providing a mirror, an abstraction of ourselves in vitro (or in silica). 

Digital Twins

# Objections to Turing Test:

- Machines don't have *souls* (some essence or intangible spark of life) and thus can't *really* be intelligent.
	- Counterpoint: If the soul is by definition immaterial, how can we know it's there? Our picture of life's origins and bounds is incomplete
- Machines can't do anything *original*.
	- Counterpoint: Are humans capable of originality? Is human behavior essentially mimetic? Is creativity a process of amalgamation, remixing, replication?
- Can an AI appreciate *beauty*?

**Searle's Chinese Room**:

From Wikipedia:
```
The machine accepts Chinese characters as input, carries out each instruction of the program step by step, and then produces Chinese characters as output. The machine does this so perfectly that no one can tell that they are communicating with a machine and not a hidden human being. The questions at issue are these: does the machine actually understand the conversation? Or is it just simulating the ability to understand the conversation? Does the machine have a mind in exactly the same sense that people do, or is it just acting as if it has a mind?
```

- Without understanding, we cannot ascribe "thinking", to the machine: It lacks a mind.
- Why Chinese Room? Pictographic languages, sequences have components that allow someone to copy sequences without understanding the language. (Turing centered linguistic capacity in his attempt to quantify AI. Fitting that Turing's major achievement was in cryptography, cracking the Enigma code.)
- It may be possible for machine intelligence to pair together sequence of words, phrases, ideas into a hash chain: essentially a lookup table. Is there any meaningful understanding if the system is nothing but a mapping function? This is ChatGPT in a nutshell.
- Is human intelligence a cypher - encrypting, decrypting input and output?
- ChatGPT is a stagnant matrix of associations. It can't learn, improve itself. 

**Block's Objection**:

Given a large enough database, it *is* possible to store a library of queries and plausible answers to mimic intelligence via table lookup. Co-frequency of common tokens into phrases and concepts, associative maps, etc. We could link through all possible logical conjunctions just through the co-frequency or "togetherness" of tokens. You can build a Chinese Room of any language.

Maybe this encoding reflects the way the brain operates, as a matrix of relations, linkages.

**Strong v. Weak AI**
- One school of thought (dominated by MIT) argues that any system demonstrating intelligent behavior is AI, regardless of internal processes. This is **Weak AI**.
- Another school (dominated by Carnegie-Mellon) holds that a system should be based on the same methods of learning and cognition used by humans. This is **Strong AI**.


