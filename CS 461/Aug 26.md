We expect AI systems to act logically and rationally more than we expect them to act *humanly*. 

Turing's argument puts emphasis on output by anonymizing input; disregards origination, internal processes in favor of external simulation of intelligence. Ship of Theseus argument: are things that share properties the same if the constitutive parts differ?

How do we think about likes, preferences, affinity in structuring our personalities? What about the emotional side of intelligence?

The Uncanny: human-like performance, but not quite human. AI chatbots resemble an animated corpse, a living object. Development of AI less about automated task-execution than providing a mirror, an abstraction of the mind in vitro (or in silica). 

**Roko's Basilisk**

From Wikipedia:
"Thought experiment which suggests an otherwise benevolent superintelligent AI in the future would be incentivized to create a virtual reality simulation to torture anyone who knew of its potential existence but did not directly contribute to its advancement or development, in order to incentivize said advancement."
```
Roko's basilisk has been viewed as a version of Pascal's wager, which proposes that a rational person should live as though God exists and seek to believe in God, regardless of the probability of God's existence, because the finite costs of believing are insignificant compared to the infinite punishment associated with not believing (eternity in Hell) and the infinite rewards for believing (eternity in Heaven). Roko's basilisk analogously proposes that a rational person should contribute to the creation of the basilisk, regardless of the probability of the basilisk ever being created, because the finite costs of contributing are insignificant compared to the eternal punishment the basilisk will inflict on simulations of his consciousness if he does not contribute.
```
The name derives from the basilisk and its destructive gaze.
# Objections to Turing Test:

- Machines don't have *souls* (some essence or intangible spark of life) and thus can't *really* be intelligent.
	- Counterpoint: If the soul is by definition immaterial, how can we know it's there? Our picture of life's origins and bounds is incomplete
- Machines can't do anything *original*.
	- Counterpoint: Are humans capable of originality? Is human behavior mimetic? Is creativity reducible to amalgamation, remixing, replication?
- Can an AI appreciate *beauty*?

**Searle's Chinese Room**:

From the slides:
```
Users pass notes written in Chinese under a door. Inside, a human, who does not know Chinese, looks them up in a series of complex rulebooks and writes out some other symbols (which he also does not understand) and passes them back out under the door. People reading those responses on the other side believe he is answering in Chinese; yet neither the person nor the rulebooks can be said to understand Chinese
```
- Without understanding, we cannot ascribe "thinking", to the machine: It lacks a mind.
- Why Chinese Room? Pictographic languages have components that allow someone to copy sequences without understanding the language. (Turing centered linguistic capacity in his attempt to quantify AI.)
- It may be possible for machine intelligence to pair together sequences of words, phrases, ideas into a hash chain: essentially a lookup table. Is there any meaningful understanding if the system is nothing but a mapping function? (e.g. ChatGPT)
- Is human intelligence a function? Or a cypher: a biological machine encrypting, decrypting input and output? (Turing's major achievement was cracking the Enigma code.)
- ChatGPT is stagnant, inert. It can't learn, improve itself. It can't ask questions.
 
**Block's Objection**:

Given a large enough database, it *is* possible to store a library of queries and plausible answers to mimic intelligence via table lookup. We could link through all possible logical conjunctions, phrases and concepts, just through the co-frequency or "togetherness" of tokens. You can build a Chinese Room of any language

Maybe this encoding reflects the brain's structure, as a matrix of relations, linkages. As a function

**Strong v. Weak AI**
- One school of thought (dominated by MIT) argues that any system demonstrating intelligent behavior is AI, regardless of internal processes. This is **Weak AI**.
- Another school (dominated by Carnegie-Mellon) holds that a system should be based on the same methods of learning and cognition used by humans. This is **Strong AI**.


