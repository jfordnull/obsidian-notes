Responsibility, "response" "-ability"; Humans have agency, a capacity to respond to changes in our environment. 

How does a Weak AI "respond" to its environment? We enumerate all possible events and map a response. Weak AI is easy to define. Weak AI proponents argue that the purpose of AI is to solve difficult problems. Its advantage is the scope of its memory framework; We assume there are patterns in the data that AI can observe beyond human capacity. Is "forgetting" a condition of intelligence? (GPTS are able to "forget")

Human thinking is interpersonal. Our consciousness is a chorus of internal voices, a consensus of smaller selves. If we develop a Strong AI, would it have an id, an ego, a superego? Would we program these patterns or would they be emergent? Has anyone ever written anything so transparent that an AI could derive the process of human thought from their work?

We should disabuse ourselves of the notion that "computational" thinking is superior. Problem of noise and interference inherent to data-collection. There is no infallible human measurement



